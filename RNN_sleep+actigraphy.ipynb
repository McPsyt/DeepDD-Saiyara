{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba265de-9012-49a0-ab17-3aaec794fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ec01e5-7bb1-4dff-ba01-a3c9be99947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"good\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"bad\" : 2\n",
    "    \n",
    "}\n",
    "def encoding(label):\n",
    "    return d[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbe5789-17a2-40df-a95f-207f81267892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetworkWithSleepData(nn.Module):\n",
    "    def __init__(self, seq_length, hidden_size, num_layers):\n",
    "        super(RecurrentNetworkWithSleepData, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=7, hidden_size=hidden_size, num_layers=num_layers, batch_first=True,  nonlinearity='relu')\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded_actigraphy_features, _ = self.rnn(x[:, :, :7])#actigraphy features\n",
    "        sleep_features = x[:, :, 7:]\n",
    "        concatenated = torch.cat((encoded_actigraphy_features, sleep_features), dim=2)\n",
    "        return self.classifier(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c5e253-bdcc-40b2-8096-cac5deedf5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, df_as_np, labels, seq_len):\n",
    "        self.data = df_as_np\n",
    "        self.labels = labels      \n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bfec75a-a275-419a-a95e-ccb3fdb758a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_data(df_as_np, labels, seq_len, batch_size=50):\n",
    "    dataset = PatientDataset(df_as_np, labels, seq_len)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b785b0-7dbc-4cb3-9aad-bcb0a091f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, seq_length, lr, epochs):\n",
    "    model = RecurrentNetworkWithSleepData(seq_length=seq_length, hidden_size=3, num_layers=10)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for seq, label in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seq.float())\n",
    "            loss = criterion(outputs, label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(epoch, batch, loss.item())\n",
    "            batch += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2bd19c-a460-4da2-83d4-b4d9c328a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    for seq, labels in dataloader:\n",
    "        output = model(seq.float())\n",
    "        pred_labels = torch.argmax(output, dim=1)\n",
    "        acc = (pred_labels == labels).float().mean().item()\n",
    "        print(acc)\n",
    "        print(pred_labels)\n",
    "        print(\"##########################\")\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4d208e-ffe0-4a9e-8b4d-4c99a811fda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['average', 'phq_9', 'cgis', 'gad_7', 'wsas', 'qids'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.read_csv(\"minute_data_007_youcef/sleep+encoded.csv\")\n",
    "df_labels = pd.read_csv(\"minute_data_007_youcef/sleep+encoded_labels.csv\")\n",
    "df_labels = df_labels.drop(columns=[\"Unnamed: 0\"])\n",
    "print(df_labels.columns)\n",
    "for col in df_labels.columns:\n",
    "    df_labels[col] =  df_labels[col].apply(encoding)\n",
    "\n",
    "df_features = df_features.drop(columns=[\"date\", \"date_only\", \"time\"]).to_numpy()[:128800,:].reshape(2576, 50, 24)\n",
    "df_labels = df_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abce270e-920d-43b2-bb8d-ad7b1f24290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### LABEL 0 #################\n",
      "0 0 1.0747333765029907\n",
      "0 1 128.43490600585938\n",
      "0 2 10.446381568908691\n",
      "0 3 5.351353645324707\n",
      "0 4 3.8651211261749268\n",
      "0 5 1.6691842079162598\n",
      "0 6 1.6057430505752563\n",
      "0 7 0.8022276163101196\n",
      "0 8 1.0506720542907715\n",
      "0 9 0.47161731123924255\n",
      "0 10 0.6595698595046997\n",
      "0 11 0.8132575750350952\n",
      "0 12 0.685547947883606\n",
      "0 13 0.6658703684806824\n",
      "0 14 0.35483384132385254\n",
      "0 15 1.3660606145858765\n",
      "0 16 0.47076842188835144\n",
      "0 17 0.9755422472953796\n",
      "0 18 6.136995792388916\n",
      "0 19 3.034501314163208\n",
      "0 20 2.3431127071380615\n",
      "1 21 1.0684345960617065\n",
      "1 22 0.95206618309021\n",
      "1 23 0.9175847768783569\n",
      "1 24 0.9577121734619141\n",
      "1 25 0.9215032458305359\n",
      "1 26 0.8595895171165466\n",
      "1 27 15430474.0\n",
      "1 28 0.808597207069397\n",
      "1 29 0.8269146680831909\n",
      "1 30 550.0515747070312\n",
      "1 31 0.835552453994751\n",
      "1 32 0.8079496026039124\n",
      "1 33 0.7627130746841431\n",
      "1 34 3.324538230895996\n",
      "1 35 0.788767397403717\n",
      "1 36 1.3255964517593384\n",
      "1 37 1.7098971605300903\n",
      "1 38 1.7856848239898682\n",
      "1 39 2.211029291152954\n",
      "1 40 1.3147393465042114\n",
      "1 41 0.9900307059288025\n",
      "2 42 2.3580925464630127\n",
      "2 43 1.1741935014724731\n",
      "2 44 2.6319925785064697\n",
      "2 45 1.721207857131958\n",
      "2 46 2.259082794189453\n",
      "2 47 2.592134952545166\n",
      "2 48 10.818394660949707\n",
      "2 49 0.45655062794685364\n",
      "2 50 0.53157639503479\n",
      "2 51 2.4578614234924316\n",
      "2 52 1.3858957290649414\n",
      "2 53 0.4501722753047943\n",
      "2 54 0.4781609773635864\n",
      "2 55 0.8445931077003479\n",
      "2 56 0.4771272540092468\n",
      "2 57 2.371473789215088\n",
      "2 58 1.0623546838760376\n",
      "2 59 0.7210720181465149\n",
      "2 60 0.5821430683135986\n",
      "2 61 0.5322600603103638\n",
      "2 62 0.5659979581832886\n",
      "3 63 0.5076173543930054\n",
      "3 64 0.6374550461769104\n",
      "3 65 0.5379447937011719\n",
      "3 66 0.5194284319877625\n",
      "3 67 0.5819891095161438\n",
      "3 68 0.6132438778877258\n",
      "3 69 0.6751621961593628\n",
      "3 70 0.633887767791748\n",
      "3 71 0.5977082252502441\n",
      "3 72 0.5828397274017334\n",
      "3 73 0.5845987796783447\n",
      "3 74 0.6090207695960999\n",
      "3 75 0.6771490573883057\n",
      "3 76 0.6054685115814209\n",
      "3 77 0.5656436085700989\n",
      "3 78 0.5878291726112366\n",
      "3 79 0.5201837420463562\n",
      "3 80 0.5912634134292603\n",
      "3 81 0.5314881205558777\n",
      "3 82 0.43848374485969543\n",
      "3 83 0.5920286178588867\n",
      "0.7300000190734863\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "##########################\n",
      "tensor([1, 2, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 1, 2, 2, 1,\n",
      "        1, 1, 1, 1, 1, 2, 2, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 2])\n",
      "############### LABEL 1 #################\n",
      "0 0 1.0897716283798218\n",
      "0 1 174.87158203125\n",
      "0 2 3.3823885917663574\n",
      "0 3 30.436769485473633\n",
      "0 4 7.772885799407959\n",
      "0 5 5.66739559173584\n",
      "0 6 2.4536237716674805\n",
      "0 7 11.432281494140625\n",
      "0 8 1.539405107498169\n",
      "0 9 1.2417224645614624\n",
      "0 10 3.166916608810425\n",
      "0 11 0.8492420315742493\n",
      "0 12 1.1100655794143677\n",
      "0 13 0.7349581718444824\n",
      "0 14 0.5945044159889221\n",
      "0 15 1.070338487625122\n",
      "0 16 1.1423065662384033\n",
      "0 17 0.6849856376647949\n",
      "0 18 0.6371423602104187\n",
      "0 19 0.9624140858650208\n",
      "0 20 0.7851657867431641\n",
      "1 21 1.3700529336929321\n",
      "1 22 0.8293933868408203\n",
      "1 23 0.6934425234794617\n",
      "1 24 0.6357353925704956\n",
      "1 25 0.7123992443084717\n",
      "1 26 0.6765668392181396\n",
      "1 27 0.569554328918457\n",
      "1 28 3.9877402782440186\n",
      "1 29 0.8021805286407471\n",
      "1 30 0.9278082251548767\n",
      "1 31 0.6689238548278809\n",
      "1 32 0.6599766612052917\n",
      "1 33 0.6510783433914185\n",
      "1 34 0.7655637264251709\n",
      "1 35 0.638171911239624\n",
      "1 36 0.6660526394844055\n",
      "1 37 0.630537748336792\n",
      "1 38 0.6105806827545166\n",
      "1 39 0.6880388855934143\n",
      "1 40 0.8445127010345459\n",
      "1 41 0.6875665783882141\n",
      "2 42 0.8467075228691101\n",
      "2 43 0.5299656391143799\n",
      "2 44 0.6420971751213074\n",
      "2 45 0.5528612732887268\n",
      "2 46 1.1340285539627075\n",
      "2 47 0.7376712560653687\n",
      "2 48 0.8525733351707458\n",
      "2 49 0.5968282222747803\n",
      "2 50 0.6184579730033875\n",
      "2 51 0.6894087195396423\n",
      "2 52 0.513627827167511\n",
      "2 53 0.6202406287193298\n",
      "2 54 0.6884742975234985\n",
      "2 55 0.6360973119735718\n",
      "2 56 0.5939882397651672\n",
      "2 57 0.8604333400726318\n",
      "2 58 0.7581422924995422\n",
      "2 59 0.7453866600990295\n",
      "2 60 0.5872892737388611\n",
      "2 61 2.4475862979888916\n",
      "2 62 0.5869110226631165\n",
      "3 63 0.8977062106132507\n",
      "3 64 1.7130504846572876\n",
      "3 65 0.7101486325263977\n",
      "3 66 0.8880487084388733\n",
      "3 67 0.8083738684654236\n",
      "3 68 0.8539948463439941\n",
      "3 69 0.7659383416175842\n",
      "3 70 0.6608319878578186\n",
      "3 71 0.6997594237327576\n",
      "3 72 0.7634862661361694\n",
      "3 73 0.6304431557655334\n",
      "3 74 0.8299604058265686\n",
      "3 75 0.621135413646698\n",
      "3 76 0.7339605689048767\n",
      "3 77 0.6086050271987915\n",
      "3 78 0.5703626275062561\n",
      "3 79 0.634249210357666\n",
      "3 80 0.6213505268096924\n",
      "3 81 0.654864490032196\n",
      "3 82 0.7674522995948792\n",
      "3 83 0.6025398373603821\n",
      "0.6800000071525574\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1,\n",
      "        1, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
      "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "##########################\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 2, 2, 0,\n",
      "        0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 0, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 1, 0,\n",
      "        1, 1, 1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 0, 0, 1, 1, 2, 1, 2, 2, 2, 0, 2, 1,\n",
      "        0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1,\n",
      "        1, 1, 1, 0])\n",
      "############### LABEL 2 #################\n",
      "0 0 1.0953409671783447\n",
      "0 1 57.102294921875\n",
      "0 2 0.3296446204185486\n",
      "0 3 0.8519647121429443\n",
      "0 4 0.3533363342285156\n",
      "0 5 0.868049144744873\n",
      "0 6 0.4542403519153595\n",
      "0 7 0.36462467908859253\n",
      "0 8 0.30357950925827026\n",
      "0 9 0.4427531063556671\n",
      "0 10 0.4378238320350647\n",
      "0 11 0.1756233423948288\n",
      "0 12 0.21613818407058716\n",
      "0 13 0.26652488112449646\n",
      "0 14 0.2391282320022583\n",
      "0 15 0.14443239569664001\n",
      "0 16 0.1378980576992035\n",
      "0 17 0.2687613368034363\n",
      "0 18 0.1683756411075592\n",
      "0 19 0.24359789490699768\n",
      "0 20 0.07810349762439728\n",
      "1 21 0.14085659384727478\n",
      "1 22 0.19118395447731018\n",
      "1 23 0.13583369553089142\n",
      "1 24 0.13234786689281464\n",
      "1 25 0.1692880094051361\n",
      "1 26 0.12343791872262955\n",
      "1 27 0.20804305374622345\n",
      "1 28 0.15911728143692017\n",
      "1 29 0.178886279463768\n",
      "1 30 0.15784531831741333\n",
      "1 31 0.27925238013267517\n",
      "1 32 0.24332071840763092\n",
      "1 33 0.1775771528482437\n",
      "1 34 0.11978849768638611\n",
      "1 35 0.10842549055814743\n",
      "1 36 0.19837285578250885\n",
      "1 37 0.14995422959327698\n",
      "1 38 0.09487254917621613\n",
      "1 39 0.17158664762973785\n",
      "1 40 0.13880549371242523\n",
      "1 41 0.18213345110416412\n",
      "2 42 0.09804227948188782\n",
      "2 43 0.09986374527215958\n",
      "2 44 0.08706849813461304\n",
      "2 45 0.1690921038389206\n",
      "2 46 0.13293027877807617\n",
      "2 47 0.11783680319786072\n",
      "2 48 0.177397683262825\n",
      "2 49 0.0655144676566124\n",
      "2 50 0.3366734981536865\n",
      "2 51 3.9491000175476074\n",
      "2 52 0.4711306691169739\n",
      "2 53 0.16042858362197876\n",
      "2 54 0.23956869542598724\n",
      "2 55 0.13637679815292358\n",
      "2 56 0.5219033360481262\n",
      "2 57 2.9386250972747803\n",
      "2 58 0.43639782071113586\n",
      "2 59 0.9685655236244202\n",
      "2 60 0.33191627264022827\n",
      "2 61 0.4995926022529602\n",
      "2 62 0.41400399804115295\n",
      "3 63 0.26572248339653015\n",
      "3 64 2.1877734661102295\n",
      "3 65 0.39379844069480896\n",
      "3 66 0.45806029438972473\n",
      "3 67 0.5447223782539368\n",
      "3 68 0.5389195084571838\n",
      "3 69 0.5209960341453552\n",
      "3 70 5.905279636383057\n",
      "3 71 0.47554919123649597\n",
      "3 72 0.46367955207824707\n",
      "3 73 4.46665096282959\n",
      "3 74 0.3788752853870392\n",
      "3 75 0.4710615873336792\n",
      "3 76 0.9737758040428162\n",
      "3 77 0.44419729709625244\n",
      "3 78 0.39247286319732666\n",
      "3 79 0.46941080689430237\n",
      "3 80 0.5176091194152832\n",
      "3 81 0.4239804446697235\n",
      "3 82 0.3720444440841675\n",
      "3 83 0.3045589327812195\n",
      "0.8899999856948853\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "##########################\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1])\n",
      "############### LABEL 3 #################\n",
      "0 0 1.0851508378982544\n",
      "0 1 19.33734703063965\n",
      "0 2 3.817775011062622\n",
      "0 3 485.327880859375\n",
      "0 4 36.36357116699219\n",
      "0 5 3.4758424758911133\n",
      "0 6 0.13083969056606293\n",
      "0 7 0.35113781690597534\n",
      "0 8 0.8849000334739685\n",
      "0 9 1.308531641960144\n",
      "0 10 2.146303176879883\n",
      "0 11 0.4490664303302765\n",
      "0 12 0.27810677886009216\n",
      "0 13 0.20832955837249756\n",
      "0 14 0.08365795761346817\n",
      "0 15 0.1505029797554016\n",
      "0 16 0.1068139523267746\n",
      "0 17 0.1171669214963913\n",
      "0 18 0.09637454152107239\n",
      "0 19 0.0715075135231018\n",
      "0 20 0.050117962062358856\n",
      "1 21 0.10763717442750931\n",
      "1 22 0.06357767432928085\n",
      "1 23 0.06655757129192352\n",
      "1 24 0.006340158171951771\n",
      "1 25 0.06285558640956879\n",
      "1 26 0.04236863926053047\n",
      "1 27 1.4371404647827148\n",
      "1 28 2.6711286409408785e-06\n",
      "1 29 0.0632086768746376\n",
      "1 30 0.07065916806459427\n",
      "1 31 0.09626232087612152\n",
      "1 32 0.3223496973514557\n",
      "1 33 0.0007278693374246359\n",
      "1 34 0.03937407582998276\n",
      "1 35 0.02216228097677231\n",
      "1 36 0.14203429222106934\n",
      "1 37 0.04357475787401199\n",
      "1 38 0.034399762749671936\n",
      "1 39 0.0003556008159648627\n",
      "1 40 0.07139859348535538\n",
      "1 41 0.027023399248719215\n",
      "2 42 0.08360511064529419\n",
      "2 43 0.015266801230609417\n",
      "2 44 0.3457009792327881\n",
      "2 45 0.38605523109436035\n",
      "2 46 0.04554227739572525\n",
      "2 47 0.06367304921150208\n",
      "2 48 0.21134208142757416\n",
      "2 49 0.02376842498779297\n",
      "2 50 0.04141700640320778\n",
      "2 51 0.07133959978818893\n",
      "2 52 0.08369986712932587\n",
      "2 53 0.03615548461675644\n",
      "2 54 0.07447030395269394\n",
      "2 55 1.1213982105255127\n",
      "2 56 0.019781574606895447\n",
      "2 57 0.035019900649785995\n",
      "2 58 0.01096938457340002\n",
      "2 59 0.010283351875841618\n",
      "2 60 0.030151350423693657\n",
      "2 61 0.03159839287400246\n",
      "2 62 0.041268859058618546\n",
      "3 63 0.03051578812301159\n",
      "3 64 0.03375355154275894\n",
      "3 65 0.05940776690840721\n",
      "3 66 0.029139501973986626\n",
      "3 67 0.02377866953611374\n",
      "3 68 0.005328793544322252\n",
      "3 69 0.02722332254052162\n",
      "3 70 0.0305005069822073\n",
      "3 71 0.2404884546995163\n",
      "3 72 0.014288222417235374\n",
      "3 73 0.07447255402803421\n",
      "3 74 0.014166162349283695\n",
      "3 75 0.04851870238780975\n",
      "3 76 0.037627533078193665\n",
      "3 77 0.055043429136276245\n",
      "3 78 0.028059596195816994\n",
      "3 79 0.02070441283285618\n",
      "3 80 0.013996063731610775\n",
      "3 81 0.06974348425865173\n",
      "3 82 0.04193557798862457\n",
      "3 83 0.02328645810484886\n",
      "0.9700000286102295\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "##########################\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "############### LABEL 4 #################\n",
      "0 0 1.114359736442566\n",
      "0 1 0.0\n",
      "0 2 0.0\n",
      "0 3 0.0\n",
      "0 4 0.0\n",
      "0 5 0.0\n",
      "0 6 0.0\n",
      "0 7 0.0\n",
      "0 8 0.0\n",
      "0 9 0.0\n",
      "0 10 0.0\n",
      "0 11 0.0\n",
      "0 12 0.0\n",
      "0 13 0.0\n",
      "0 14 0.0\n",
      "0 15 0.0\n",
      "0 16 0.0\n",
      "0 17 0.0\n",
      "0 18 0.0\n",
      "0 19 0.0\n",
      "0 20 0.0\n",
      "1 21 0.0\n",
      "1 22 0.0\n",
      "1 23 0.0\n",
      "1 24 0.0\n",
      "1 25 0.0\n",
      "1 26 0.0\n",
      "1 27 0.0\n",
      "1 28 0.0\n",
      "1 29 0.0\n",
      "1 30 0.0\n",
      "1 31 0.0\n",
      "1 32 0.0\n",
      "1 33 0.0\n",
      "1 34 0.0\n",
      "1 35 0.0\n",
      "1 36 0.0\n",
      "1 37 0.0\n",
      "1 38 0.0\n",
      "1 39 0.0\n",
      "1 40 0.0\n",
      "1 41 0.0\n",
      "2 42 0.0\n",
      "2 43 0.0\n",
      "2 44 0.0\n",
      "2 45 0.0\n",
      "2 46 0.0\n",
      "2 47 0.0\n",
      "2 48 0.0\n",
      "2 49 0.0\n",
      "2 50 0.0\n",
      "2 51 0.0\n",
      "2 52 0.0\n",
      "2 53 0.0\n",
      "2 54 0.0\n",
      "2 55 0.0\n",
      "2 56 0.0\n",
      "2 57 0.0\n",
      "2 58 0.0\n",
      "2 59 0.0\n",
      "2 60 0.0\n",
      "2 61 0.0\n",
      "2 62 0.0\n",
      "3 63 0.0\n",
      "3 64 0.0\n",
      "3 65 0.0\n",
      "3 66 0.0\n",
      "3 67 0.0\n",
      "3 68 0.0\n",
      "3 69 0.0\n",
      "3 70 0.0\n",
      "3 71 0.0\n",
      "3 72 0.0\n",
      "3 73 0.0\n",
      "3 74 0.0\n",
      "3 75 0.0\n",
      "3 76 0.0\n",
      "3 77 0.0\n",
      "3 78 0.0\n",
      "3 79 0.0\n",
      "3 80 0.0\n",
      "3 81 0.0\n",
      "3 82 0.0\n",
      "3 83 0.0\n",
      "1.0\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "##########################\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "############### LABEL 5 #################\n",
      "0 0 1.1653403043746948\n",
      "0 1 320.4010009765625\n",
      "0 2 4.546257495880127\n",
      "0 3 2.682478427886963\n",
      "0 4 2.33774471282959\n",
      "0 5 17.275846481323242\n",
      "0 6 7.0281805992126465\n",
      "0 7 0.9620445370674133\n",
      "0 8 1.4296330213546753\n",
      "0 9 1.3341822624206543\n",
      "0 10 0.9764078259468079\n",
      "0 11 0.9782677292823792\n",
      "0 12 1.0005241632461548\n",
      "0 13 0.8995437622070312\n",
      "0 14 0.9113274216651917\n",
      "0 15 1.5764693021774292\n",
      "0 16 0.7592591047286987\n",
      "0 17 0.7590104937553406\n",
      "0 18 0.8245487809181213\n",
      "0 19 1.5935484170913696\n",
      "0 20 1.1012015342712402\n",
      "1 21 0.8562429547309875\n",
      "1 22 0.7334203124046326\n",
      "1 23 0.9022719860076904\n",
      "1 24 0.7622268795967102\n",
      "1 25 0.871284544467926\n",
      "1 26 0.615567684173584\n",
      "1 27 0.9240749478340149\n",
      "1 28 0.9041358828544617\n",
      "1 29 1.082379937171936\n",
      "1 30 0.7234175205230713\n",
      "1 31 0.7967900633811951\n",
      "1 32 0.6737440228462219\n",
      "1 33 0.6858162879943848\n",
      "1 34 0.6606600284576416\n",
      "1 35 0.8807228803634644\n",
      "1 36 0.7083492279052734\n",
      "1 37 0.8799934983253479\n",
      "1 38 48.36069869995117\n",
      "1 39 0.9997150897979736\n",
      "1 40 0.9886608719825745\n",
      "1 41 0.8275853991508484\n",
      "2 42 0.8122041821479797\n",
      "2 43 1.6917566061019897\n",
      "2 44 0.9225722551345825\n",
      "2 45 0.8319525122642517\n",
      "2 46 0.8392727375030518\n",
      "2 47 0.8774061799049377\n",
      "2 48 0.8086583614349365\n",
      "2 49 0.722777247428894\n",
      "2 50 0.7165115475654602\n",
      "2 51 0.7655346393585205\n",
      "2 52 0.7591127157211304\n",
      "2 53 0.7766443490982056\n",
      "2 54 0.6695920825004578\n",
      "2 55 0.8711881041526794\n",
      "2 56 0.8424791097640991\n",
      "2 57 0.6963462829589844\n",
      "2 58 0.6705862283706665\n",
      "2 59 1.3021016120910645\n",
      "2 60 1.2005788087844849\n",
      "2 61 0.8119137287139893\n",
      "2 62 0.6811343431472778\n",
      "3 63 0.752688467502594\n",
      "3 64 0.7701306939125061\n",
      "3 65 0.6983032822608948\n",
      "3 66 0.76506507396698\n",
      "3 67 0.8374980092048645\n",
      "3 68 1.3438798189163208\n",
      "3 69 0.7353576421737671\n",
      "3 70 0.5935801863670349\n",
      "3 71 0.7698097825050354\n",
      "3 72 0.6975634694099426\n",
      "3 73 0.6960822343826294\n",
      "3 74 0.6809864044189453\n",
      "3 75 0.6844099164009094\n",
      "3 76 1.124650478363037\n",
      "3 77 0.6728212237358093\n",
      "3 78 0.7157991528511047\n",
      "3 79 0.8195432424545288\n",
      "3 80 0.6499250531196594\n",
      "3 81 0.8235858082771301\n",
      "3 82 0.784954309463501\n",
      "3 83 0.7034316658973694\n",
      "0.6800000071525574\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "##########################\n",
      "tensor([2, 1, 1, 0, 2, 1, 0, 2, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1,\n",
      "        0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 1, 1,\n",
      "        1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(f\"############### LABEL {i} #################\")\n",
    "    train_loader, val_loader, test_loader =load_patient_data(df_features, df_labels[:, i], seq_len=50, batch_size=100)\n",
    "    model = train(dataloader=train_loader, lr=0.05, epochs=4, seq_length=50)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06106e43-6e8d-4e96-a54a-71be811d421b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env2",
   "language": "python",
   "name": "virtual_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
