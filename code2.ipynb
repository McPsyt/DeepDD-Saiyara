{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6936032d-d8b3-4cf6-ab12-2f12e54e62f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T17:04:24.477274Z",
     "start_time": "2025-08-18T17:03:01.320956Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa1910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1fd5d2-fad7-49b0-beaa-a79892d801ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(parquet):\n",
    "    df = pd.read_parquet(parquet)\n",
    "\n",
    "    actual_first_row = df.columns.to_list()\n",
    "    new_headers = [\"date_time\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "    df.columns = new_headers\n",
    "    df.loc[-1] = actual_first_row\n",
    "    df.index = df.index + 1\n",
    "    df = df.sort_index()\n",
    "    df.columns = new_headers\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322e42e8-ed0e-4730-b37d-dc7daf47f93f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T17:09:58.801231Z",
     "start_time": "2025-08-18T17:09:58.798876Z"
    }
   },
   "outputs": [],
   "source": [
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, seq_length, hidden_size, num_layers):\n",
    "        self.rnn = nn.RNN(input_size=seq_length, hidden_size=hidden_size, num_layers=num_layers, batch_first=True,  nonlinearity='relu')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86ff9ee-7f8a-404b-867a-b0d687e15d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T17:10:06.604071Z",
     "start_time": "2025-08-18T17:10:06.602286Z"
    }
   },
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, df_as_np, seq_len):\n",
    "        self.data = df_as_np\n",
    "      \n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx:idx+self.seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db58e6d0-2c32-4597-ae8c-7fb01ca52f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T17:10:10.342705Z",
     "start_time": "2025-08-18T17:10:10.340764Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_patient_data(df_as_np, seq_len, batch_size=100):\n",
    "    dataset = PatientDataset(df_as_np, seq_len)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f450738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_encoding(date_time_string):\n",
    "    date_string = date_time_string.split(\" \")[0]\n",
    "    date_object = datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "    return date_object.weekday()/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae97dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_encoding(date_time_string):\n",
    "    time = date_time_string.split(\" \")[1]\n",
    "    splitted = time.split(\":\")\n",
    "    hour = int(splitted[0])\n",
    "    minute = int(splitted[1])\n",
    "    second = int(splitted[2])\n",
    "    millisecond = int(splitted[3])\n",
    "    l = [hour, minute, second, millisecond]\n",
    "    arr = np.array(l, dtype=np.float64)\n",
    "\n",
    "    arr[1] /= 60\n",
    "    arr[2] /= 3600\n",
    "    arr[3] /= 3600000\n",
    "\n",
    "    total_hours = arr[0] + arr[1] + arr[2] + arr[3]\n",
    "\n",
    "    return total_hours/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d042c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actiography_features_encoding(df, feature):\n",
    "    df[feature] = df[feature].astype(float)\n",
    "    mean = df[feature].mean()\n",
    "    sd = math.sqrt(df[feature].var())\n",
    "    df[feature] = (df[feature]-mean)/sd\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f512cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df_to_array(df):\n",
    "    df[\"date_encoded\"] = df[\"date_time\"].apply(date_encoding)\n",
    "    df[\"time_encoded\"] = df[\"date_time\"].apply(time_encoding)\n",
    "    actiography_features = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "    for f in actiography_features:\n",
    "        if f != \"E\":\n",
    "            df = actiography_features_encoding(df=df, feature=f)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e7fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2025-06-17 12:50:10:000  0.0348  1.0717  -0.1336  287  0  42.2\n",
      "0  2025-06-17 12:50:10:020  0.0777  0.9572  -0.0659  287  0  42.2\n",
      "1  2025-06-17 12:50:10:040  0.0153  1.0243  -0.0619  270  0  42.2\n",
      "2  2025-06-17 12:50:10:060 -0.0511  1.0717  -0.0738  270  0  42.2\n",
      "3  2025-06-17 12:50:10:080  0.0465  0.9493  -0.0619  287  0  42.2\n",
      "4  2025-06-17 12:50:10:100  0.0699  0.9651  -0.0260  287  0  42.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"parquet/DD_04_2025_019/Month 2/DD042025019_left wrist_101696_2025-07-15 11-53-15.parquet\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c223af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date_time         A         B         C         D   E  \\\n",
      "index                                                                        \n",
      "0      2025-01-30 12:10:05:000  2.441999 -0.365826 -0.354713  0.628275 NaN   \n",
      "1      2025-01-30 12:10:05:020  2.505794 -0.480054 -0.445056  0.633710 NaN   \n",
      "2      2025-01-30 12:10:05:040  2.473996 -0.569790 -0.451497  0.633710 NaN   \n",
      "3      2025-01-30 12:10:05:060  2.665382 -0.586050 -0.451497  0.639145 NaN   \n",
      "4      2025-01-30 12:10:05:080  2.649483 -0.259625 -0.516074  0.639145 NaN   \n",
      "\n",
      "              F  date_encoded  time_encoded  \n",
      "index                                        \n",
      "0      1.430924      0.428571      0.507002  \n",
      "1      1.430924      0.428571      0.507003  \n",
      "2      1.430924      0.428571      0.507003  \n",
      "3      1.430924      0.428571      0.507003  \n",
      "4      1.430924      0.428571      0.507003  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"cleaned_parquet/007/Month 7/DD072024007__100889_2025-03-26 12-05-58.parquet\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
