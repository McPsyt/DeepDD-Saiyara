{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b8110-4962-47a4-a360-dbd6e63d0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138654d7-e834-4df8-a4fe-25eebde9c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"good\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"bad\" : 2\n",
    "    \n",
    "}\n",
    "def encoding(label):\n",
    "    return d[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53d07e-3a0a-4884-9521-71ff4df787e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, df_as_np, labels, seq_len):\n",
    "        self.data = df_as_np\n",
    "        self.labels = labels      \n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac235c7-0e1d-4d54-9f94-62fdd8ede112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_data(df_as_np, labels, seq_len, batch_size=50):\n",
    "    dataset = PatientDataset(df_as_np, labels, seq_len)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3074c-2a1b-4db7-a93f-79c946dee114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, seq_length, hidden_size, num_layers):\n",
    "        super(RecurrentNetwork, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=7, hidden_size=hidden_size, num_layers=num_layers, batch_first=True,  nonlinearity='relu')\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(seq_length*hidden_size,3),           \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f4d9e-c55a-407c-ac15-5c723869a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, seq_length, lr, epochs):\n",
    "    model = RecurrentNetwork(seq_length=seq_length, hidden_size=3, num_layers=10)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for seq, label in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seq.float())\n",
    "            loss = criterion(outputs, label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(epoch, batch, loss.item())\n",
    "            batch += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e248631-f51e-4d56-ad64-bce845d57355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_target(df_features_as_np, df_labels_as_np, i, seq_len):\n",
    "    train_loader, val_loader, test_loader = load_patient_data(df_features_as_np, df_labels_as_np[:, i], seq_len=seq_len, batch_size=500)\n",
    "    return train_loader, val_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa18fb7-1f4d-46dd-9f74-60bca3437dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    for seq, labels in dataloader:\n",
    "        output = model(seq.float())\n",
    "        pred_labels = torch.argmax(output, dim=1)\n",
    "        acc = (pred_labels == labels).float().mean().item()\n",
    "        print(acc)\n",
    "        print(pred_labels)\n",
    "        print(\"##########################\")\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c48e04-97cb-4415-9af3-91f266ccc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(csv_features, csv_labels, feature_cols_to_drop, label_cols_to_drop, features_range, features_shape, seq_len):\n",
    "    df_features= pd.read_csv(csv_features)\n",
    "    df_labels = pd.read_csv(csv_labels)\n",
    "    df_features = df_features.drop(columns=feature_cols_to_drop)\n",
    "    df_labels = df_labels.drop(columns=label_cols_to_drop)\n",
    "    for column in df_labels.columns:\n",
    "        df_labels[column] = df_labels[column].apply(encoding)\n",
    "    df_features_as_np = df_features.to_numpy()[:features_range,:]\n",
    "    df_features_as_np = df_features_as_np.reshape(features_shape)\n",
    "    df_labels_as_np = df_labels.to_numpy()\n",
    "\n",
    "    print(\"pre_train shapes\")\n",
    "    print(df_features_as_np.shape)\n",
    "    print(df_labels_as_np.shape)\n",
    "    \n",
    "    for i in range(6):\n",
    "        print(f\"############### LABEL {i} #################\")\n",
    "        train_loader, val_loader, test_loader = select_target(df_features_as_np, df_labels_as_np, i, seq_len)\n",
    "        model = train(dataloader=train_loader, lr=0.05, epochs=4, seq_length=seq_len)\n",
    "        print(\"################# TESTING ##############################\")\n",
    "        test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2f18e-8784-42a6-ad6f-7ad59854e6bb",
   "metadata": {},
   "source": [
    "Youcef's minute data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e78c86-9bda-47be-be5a-4627be552c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"minute_data_007_youcef/encoded.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e5019-0a65-4bc5-9c34-2afd4d6ae990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"minute_data_007_youcef/labels.csv\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf633f8b-bf2a-4084-a9fe-d2088ad8265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(csv_features=\"minute_data_007_youcef/encoded.csv\", csv_labels=\"minute_data_007_youcef/labels.csv\", feature_cols_to_drop=['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'date', 'date_only', 'time'], label_cols_to_drop=['Unnamed: 0'], features_range=180950, features_shape=(3619, 50, 7), seq_len=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d4b28-df28-48a0-91bc-94eecafe0567",
   "metadata": {},
   "source": [
    "2s data, seq len of 10, randomly sampled, months 2-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f69f9a-30ea-4631-ab35-08166cfd1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_1_seq_len_10/sample_features.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae33ce5-65cc-49cf-995c-23f2029e27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_1_seq_len_10/sample_labels.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac8c41-bdb7-48d7-9ee2-d29e87a37605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(csv_features=\"cleaned_parquet/007/sample_1_seq_len_10/sample_features.csv\", csv_labels=\"cleaned_parquet/007/sample_1_seq_len_10/sample_labels.csv\", feature_cols_to_drop=['Unnamed: 0.1', 'Unnamed: 0', 'date_time', \"date\", \"E\"], label_cols_to_drop=['Unnamed: 0.1','Unnamed: 0'], features_range=240000, features_shape=(24000, 10, 7), seq_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9266730-ae59-4a7a-bc1c-335f45b12420",
   "metadata": {},
   "source": [
    "2s data, seq len of 50, randomly sampled, months 2-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b0f74-e059-4737-a356-6f43a60a87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_2_seq_len_50/sample_features.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc9e3f-eb07-4fa3-bc10-661210c77c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_2_seq_len_50/sample_labels.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcb7de-fe91-444f-a08b-6b04ddcc82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(csv_features=\"cleaned_parquet/007/sample_2_seq_len_50/sample_features.csv\", csv_labels=\"cleaned_parquet/007/sample_2_seq_len_50/sample_labels.csv\", feature_cols_to_drop=['Unnamed: 0.1', 'Unnamed: 0', 'date_time', \"date\", \"E\"], label_cols_to_drop=['Unnamed: 0.1','Unnamed: 0'], features_range=1200000, features_shape=(24000, 50, 7), seq_len=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d57f36-b62b-4979-a9d3-5ffcbb7676ad",
   "metadata": {},
   "source": [
    "2s data, seq len of 10, randomly sampled, months 3, 4, 6. I'll only train for \"average\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4608489-a283-46ee-a850-1f74e4b7a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_only_avg(par_dir, features_arr_shape, labels_arr_shape, seq_len):\n",
    "    df_3_features = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_3.csv\")\n",
    "    df_3_labels = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_3_labels.csv\")\n",
    "    \n",
    "    df_4_features = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_4.csv\")\n",
    "    df_4_labels = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_4_labels.csv\")\n",
    "    \n",
    "    df_6_features = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_6.csv\")\n",
    "    df_6_labels = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_6_labels.csv\")\n",
    "    \n",
    "    df_feature_rows_all = pd.concat([df_3_features, df_4_features, df_6_features])\n",
    "    df_all_label_rows = pd.concat([df_3_labels, df_4_labels, df_6_labels])\n",
    "    \n",
    "    df_feature_rows_all = df_feature_rows_all.drop(columns=['Unnamed: 0', 'date_time', \"date\", \"E\"])\n",
    "    \n",
    "    df_all_label_rows[\"average\"] = df_all_label_rows[\"average\"].apply(encoding)\n",
    "    \n",
    "    df_as_np = df_feature_rows_all.to_numpy().reshape(features_arr_shape)\n",
    "    labels = df_all_label_rows[\"average\"].to_numpy().reshape(labels_arr_shape)\n",
    "\n",
    "    \n",
    "    train_loader, val_loader, test_loader = select_target(df_features_as_np=df_as_np, df_labels_as_np=labels, i=0, seq_len=seq_len)\n",
    "    model = train(dataloader=train_loader, lr=0.05, epochs=4, seq_length=seq_len)\n",
    "    test(model, dataloader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2246450-377e-449c-ab4d-8dcf69cccbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_only_avg(par_dir=\"sample_1_seq_len_10\", features_arr_shape=(12000, 10, 7), labels_arr_shape=(12000, 1), seq_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c05eb-ab2c-461b-93d0-f0aa54718e9a",
   "metadata": {},
   "source": [
    "2s data, seq len of 50, randomly sampled, months 3, 4, 6. I'll only train for \"average\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65af184-05e3-4481-9b7e-eb792bf9e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_only_avg(par_dir=\"sample_2_seq_len_50\", features_arr_shape=(12000, 50, 7), labels_arr_shape=(12000, 1), seq_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3a2a9-5ce9-415f-80cf-6d223596e016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env2",
   "language": "python",
   "name": "virtual_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
