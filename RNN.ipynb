{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85b8110-4962-47a4-a360-dbd6e63d0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138654d7-e834-4df8-a4fe-25eebde9c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"good\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"bad\" : 2\n",
    "    \n",
    "}\n",
    "def encoding(label):\n",
    "    return d[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be53d07e-3a0a-4884-9521-71ff4df787e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, df_as_np, labels, seq_len):\n",
    "        self.data = df_as_np\n",
    "        self.labels = labels      \n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac235c7-0e1d-4d54-9f94-62fdd8ede112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_data(df_as_np, labels, seq_len, batch_size=50):\n",
    "    dataset = PatientDataset(df_as_np, labels, seq_len)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87a3074c-2a1b-4db7-a93f-79c946dee114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, seq_length, hidden_size, num_layers):\n",
    "        super(RecurrentNetwork, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=7, hidden_size=hidden_size, num_layers=num_layers, batch_first=True,  nonlinearity='relu')\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(seq_length*3,3),           \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "233f4d9e-c55a-407c-ac15-5c723869a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, seq_length, lr, epochs):\n",
    "    model = RecurrentNetwork(seq_length=seq_length, hidden_size=3, num_layers=10)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for seq, label in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seq.float())\n",
    "            loss = criterion(outputs, label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(epoch, batch, loss.item())\n",
    "            batch += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e248631-f51e-4d56-ad64-bce845d57355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_target(df_features_as_np, df_labels_as_np, i, seq_len):\n",
    "    train_loader, val_loader, test_loader = load_patient_data(df_features_as_np, df_labels_as_np[:, i], seq_len=seq_len, batch_size=500)\n",
    "    return train_loader, val_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa18fb7-1f4d-46dd-9f74-60bca3437dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    for seq, labels in dataloader:\n",
    "        output = model(seq.float())\n",
    "        pred_labels = torch.argmax(output, dim=1)\n",
    "        acc = (pred_labels == labels).float().mean().item()\n",
    "        print(acc)\n",
    "        print(pred_labels)\n",
    "        print(\"##########################\")\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61c48e04-97cb-4415-9af3-91f266ccc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(csv_features, csv_labels, feature_cols_to_drop, label_cols_to_drop, features_range, features_shape, seq_len):\n",
    "    df_features= pd.read_csv(csv_features)\n",
    "    df_labels = pd.read_csv(csv_labels)\n",
    "    df_features = df_features.drop(columns=feature_cols_to_drop)\n",
    "    df_labels = df_labels.drop(columns=label_cols_to_drop)\n",
    "    for column in df_labels.columns:\n",
    "        df_labels[column] = df_labels[column].apply(encoding)\n",
    "    df_features_as_np = df_features.to_numpy()[:features_range,:]\n",
    "    df_features_as_np = df_features_as_np.reshape(features_shape)\n",
    "    df_labels_as_np = df_labels.to_numpy()\n",
    "\n",
    "    print(\"pre_train shapes\")\n",
    "    print(df_features_as_np.shape)\n",
    "    print(df_labels_as_np.shape)\n",
    "    \n",
    "    for i in range(6):\n",
    "        print(f\"############### LABEL {i} #################\")\n",
    "        train_loader, val_loader, test_loader = select_target(df_features_as_np, df_labels_as_np, i, seq_len)\n",
    "        model = train(dataloader=train_loader, lr=0.05, epochs=4, seq_length=seq_len)\n",
    "        print(\"################# TESTING ##############################\")\n",
    "        test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2f18e-8784-42a6-ad6f-7ad59854e6bb",
   "metadata": {},
   "source": [
    "Youcef's minute data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e78c86-9bda-47be-be5a-4627be552c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"minute_data_007_youcef/encoded.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e5019-0a65-4bc5-9c34-2afd4d6ae990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"minute_data_007_youcef/labels.csv\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf633f8b-bf2a-4084-a9fe-d2088ad8265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(csv_features=\"minute_data_007_youcef/encoded.csv\", csv_labels=\"minute_data_007_youcef/labels.csv\", feature_cols_to_drop=['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'date', 'date_only', 'time'], label_cols_to_drop=['Unnamed: 0'], features_range=180950, features_shape=(3619, 50, 7), seq_len=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d4b28-df28-48a0-91bc-94eecafe0567",
   "metadata": {},
   "source": [
    "2s data, seq len of 10, randomly sampled, months 2-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f69f9a-30ea-4631-ab35-08166cfd1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_1_seq_len_10/sample_features.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae33ce5-65cc-49cf-995c-23f2029e27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_1_seq_len_10/sample_labels.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac8c41-bdb7-48d7-9ee2-d29e87a37605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(csv_features=\"cleaned_parquet/007/sample_1_seq_len_10/sample_features.csv\", csv_labels=\"cleaned_parquet/007/sample_1_seq_len_10/sample_labels.csv\", feature_cols_to_drop=['Unnamed: 0.1', 'Unnamed: 0', 'date_time', \"date\", \"E\"], label_cols_to_drop=['Unnamed: 0.1','Unnamed: 0'], features_range=240000, features_shape=(24000, 10, 7), seq_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9266730-ae59-4a7a-bc1c-335f45b12420",
   "metadata": {},
   "source": [
    "2s data, seq len of 50, randomly sampled, months 2-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b0f74-e059-4737-a356-6f43a60a87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_2_seq_len_50/sample_features.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc9e3f-eb07-4fa3-bc10-661210c77c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_parquet/007/sample_2_seq_len_50/sample_labels.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcb7de-fe91-444f-a08b-6b04ddcc82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(csv_features=\"cleaned_parquet/007/sample_2_seq_len_50/sample_features.csv\", csv_labels=\"cleaned_parquet/007/sample_2_seq_len_50/sample_labels.csv\", feature_cols_to_drop=['Unnamed: 0.1', 'Unnamed: 0', 'date_time', \"date\", \"E\"], label_cols_to_drop=['Unnamed: 0.1','Unnamed: 0'], features_range=1200000, features_shape=(24000, 50, 7), seq_len=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d57f36-b62b-4979-a9d3-5ffcbb7676ad",
   "metadata": {},
   "source": [
    "2s data, seq len of 10, randomly sampled, months 3, 4, 6. I'll only train for \"average\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4608489-a283-46ee-a850-1f74e4b7a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_only_avg(par_dir, features_arr_shape, labels_arr_shape, seq_len):\n",
    "    df_3_features = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_3.csv\")\n",
    "    df_3_labels = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_3_labels.csv\")\n",
    "    \n",
    "    df_4_features = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_4.csv\")\n",
    "    df_4_labels = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_4_labels.csv\")\n",
    "    \n",
    "    df_6_features = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_6.csv\")\n",
    "    df_6_labels = pd.read_csv(f\"cleaned_parquet/007/{par_dir}/month_6_labels.csv\")\n",
    "    \n",
    "    df_feature_rows_all = pd.concat([df_3_features, df_4_features, df_6_features])\n",
    "    df_all_label_rows = pd.concat([df_3_labels, df_4_labels, df_6_labels])\n",
    "    \n",
    "    df_feature_rows_all = df_feature_rows_all.drop(columns=['Unnamed: 0', 'date_time', \"date\", \"E\"])\n",
    "    \n",
    "    df_all_label_rows[\"average\"] = df_all_label_rows[\"average\"].apply(encoding)\n",
    "    \n",
    "    df_as_np = df_feature_rows_all.to_numpy().reshape(features_arr_shape)\n",
    "    labels = df_all_label_rows[\"average\"].to_numpy().reshape(labels_arr_shape)\n",
    "\n",
    "    \n",
    "    train_loader, val_loader, test_loader = select_target(df_features_as_np=df_as_np, df_labels_as_np=labels, i=0, seq_len=seq_len)\n",
    "    model = train(dataloader=train_loader, lr=0.05, epochs=4, seq_length=seq_len)\n",
    "    test(model, dataloader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2246450-377e-449c-ab4d-8dcf69cccbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_only_avg(par_dir=\"sample_1_seq_len_10\", features_arr_shape=(12000, 10, 7), labels_arr_shape=(12000, 1), seq_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c05eb-ab2c-461b-93d0-f0aa54718e9a",
   "metadata": {},
   "source": [
    "2s data, seq len of 50, randomly sampled, months 3, 4, 6. I'll only train for \"average\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b65af184-05e3-4481-9b7e-eb792bf9e815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.2231528759002686\n",
      "0 1 4.316273212432861\n",
      "0 2 3.7468833923339844\n",
      "0 3 1.5085508823394775\n",
      "0 4 1.127094030380249\n",
      "0 5 1.1511147022247314\n",
      "0 6 1.2539817094802856\n",
      "0 7 1.1142102479934692\n",
      "0 8 1.1036556959152222\n",
      "0 9 1.1060819625854492\n",
      "0 10 1.0972312688827515\n",
      "0 11 1.1003899574279785\n",
      "0 12 1.1003321409225464\n",
      "0 13 1.099125623703003\n",
      "0 14 1.1011409759521484\n",
      "0 15 1.1040444374084473\n",
      "0 16 1.1022144556045532\n",
      "0 17 1.1009526252746582\n",
      "0 18 1.0998716354370117\n",
      "0 19 1.0987277030944824\n",
      "1 20 1.0997847318649292\n",
      "1 21 1.100624918937683\n",
      "1 22 1.0998942852020264\n",
      "1 23 1.097243070602417\n",
      "1 24 1.0991166830062866\n",
      "1 25 1.0989850759506226\n",
      "1 26 1.0999258756637573\n",
      "1 27 1.0978045463562012\n",
      "1 28 1.0979042053222656\n",
      "1 29 1.0991344451904297\n",
      "1 30 1.0987861156463623\n",
      "1 31 1.0989739894866943\n",
      "1 32 1.0989238023757935\n",
      "1 33 1.09808349609375\n",
      "1 34 1.0982314348220825\n",
      "1 35 1.0990158319473267\n",
      "1 36 1.0994009971618652\n",
      "1 37 1.0977013111114502\n",
      "1 38 1.100135087966919\n",
      "1 39 1.098105788230896\n",
      "2 40 1.0970005989074707\n",
      "2 41 1.0978676080703735\n",
      "2 42 1.0990413427352905\n",
      "2 43 1.0991239547729492\n",
      "2 44 1.1002254486083984\n",
      "2 45 1.1001533269882202\n",
      "2 46 1.0988359451293945\n",
      "2 47 1.0985448360443115\n",
      "2 48 1.0989646911621094\n",
      "2 49 1.0991352796554565\n",
      "2 50 1.099088191986084\n",
      "2 51 1.0984370708465576\n",
      "2 52 1.098602294921875\n",
      "2 53 1.0989879369735718\n",
      "2 54 1.1005892753601074\n",
      "2 55 1.0989042520523071\n",
      "2 56 1.0987982749938965\n",
      "2 57 1.0984834432601929\n",
      "2 58 1.098439335823059\n",
      "2 59 1.0989731550216675\n",
      "3 60 1.0986450910568237\n",
      "3 61 1.0986886024475098\n",
      "3 62 1.0984923839569092\n",
      "3 63 1.098425269126892\n",
      "3 64 1.0993469953536987\n",
      "3 65 1.0996754169464111\n",
      "3 66 1.09848153591156\n",
      "3 67 1.0978717803955078\n",
      "3 68 1.0991045236587524\n",
      "3 69 1.0987966060638428\n",
      "3 70 1.0986342430114746\n",
      "3 71 1.09922456741333\n",
      "3 72 1.0986697673797607\n",
      "3 73 1.0988078117370605\n",
      "3 74 1.0984784364700317\n",
      "3 75 1.0994940996170044\n",
      "3 76 1.0987643003463745\n",
      "3 77 1.099802851676941\n",
      "3 78 1.0984045267105103\n",
      "3 79 1.0981444120407104\n",
      "0.3059999942779541\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "##########################\n",
      "tensor([1, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 2, 2, 0, 0, 2, 2, 1, 0, 0, 0, 2, 1, 2,\n",
      "        2, 1, 1, 2, 0, 1, 2, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0, 2, 0, 1, 1, 2,\n",
      "        2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2,\n",
      "        1, 1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1, 0, 0, 2,\n",
      "        1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "        0, 1, 1, 2, 1, 0, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 2, 1, 1, 1, 0, 2, 0, 2,\n",
      "        1, 0, 2, 1, 2, 1, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2,\n",
      "        1, 0, 0, 2, 2, 2, 0, 1, 2, 2, 2, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 2, 1, 0,\n",
      "        1, 2, 0, 1, 2, 2, 1, 1, 0, 1, 0, 2, 2, 2, 1, 0, 1, 2, 1, 2, 0, 0, 0, 1,\n",
      "        0, 2, 2, 2, 2, 2, 2, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 0, 0, 2, 0, 2, 1,\n",
      "        2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 2, 0, 2, 2,\n",
      "        1, 1, 0, 0, 2, 2, 0, 1, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 0, 1, 2, 0, 2, 1,\n",
      "        2, 0, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 0, 1, 0, 2, 1, 1, 1, 1, 2, 1, 0, 0,\n",
      "        1, 2, 1, 2, 0, 0, 0, 2, 2, 1, 2, 2, 2, 0, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0,\n",
      "        1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 1, 0, 2, 2, 1,\n",
      "        0, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 0, 2, 0, 2, 0,\n",
      "        0, 1, 2, 0, 1, 1, 0, 2, 2, 2, 0, 1, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 1, 2, 1, 1, 0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "train_and_test_only_avg(par_dir=\"sample_2_seq_len_50\", features_arr_shape=(12000, 50, 7), labels_arr_shape=(12000, 1), seq_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3a2a9-5ce9-415f-80cf-6d223596e016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env2",
   "language": "python",
   "name": "virtual_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
