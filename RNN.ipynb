{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85b8110-4962-47a4-a360-dbd6e63d0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138654d7-e834-4df8-a4fe-25eebde9c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"good\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"bad\" : 2\n",
    "    \n",
    "}\n",
    "def encoding(label):\n",
    "    return d[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be53d07e-3a0a-4884-9521-71ff4df787e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, df_as_np, labels, seq_len):\n",
    "        self.data = df_as_np\n",
    "        self.labels = labels      \n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac235c7-0e1d-4d54-9f94-62fdd8ede112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_data(df_as_np, labels, seq_len, batch_size=500):\n",
    "    dataset = PatientDataset(df_as_np, labels, seq_len)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a3074c-2a1b-4db7-a93f-79c946dee114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, seq_length, hidden_size, num_layers):\n",
    "        super(RecurrentNetwork, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=8, hidden_size=hidden_size, num_layers=num_layers, batch_first=True,  nonlinearity='relu')\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(30,3),           \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a5b3f65-1eef-48f6-8103-98db792602c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 10, 8)\n",
      "(24000, 6)\n",
      "[[2 1 1 2 1 2]\n",
      " [2 1 1 2 1 2]\n",
      " [2 1 1 2 1 2]\n",
      " ...\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1]\n",
      " [1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "df_features= pd.read_csv(\"cleaned_parquet/007/sample_features.csv\")\n",
    "df_labels = pd.read_csv(\"cleaned_parquet/007/sample_labels.csv\")\n",
    "df_features = df_features.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\", \"date_time\", \"date\"])\n",
    "df_labels = df_labels.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])\n",
    "for column in df_labels.columns:\n",
    "    df_labels[column] = df_labels[column].apply(encoding)\n",
    "\n",
    "df_features_as_np = df_features.to_numpy()\n",
    "df_features_as_np = df_features_as_np.reshape(24000, 10, 8)\n",
    "df_labels_as_np = df_labels.to_numpy()\n",
    "print(df_features_as_np.shape)\n",
    "print(df_labels_as_np.shape)\n",
    "print(df_labels_as_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "233f4d9e-c55a-407c-ac15-5c723869a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, lr, epochs):\n",
    "    model = RecurrentNetwork(seq_length=10, hidden_size=3, num_layers=10)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    batch = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for seq, label in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seq.float())\n",
    "            loss = criterion(outputs, label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(epoch, batch, loss.item())\n",
    "            batch += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e248631-f51e-4d56-ad64-bce845d57355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_target(i):\n",
    "    train_loader, val_loader, test_loader = load_patient_data(df_features_as_np, df_labels_as_np[:, i], seq_len=10, batch_size=500)\n",
    "    return train_loader, val_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "492cf264-8752-4b64-a2da-c76f04d4f8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.0236643552780151\n",
      "0 1 1.0146995782852173\n",
      "0 2 1.010332465171814\n",
      "0 3 1.01027250289917\n",
      "0 4 0.9908196926116943\n",
      "0 5 0.9943972826004028\n",
      "0 6 1.0128597021102905\n",
      "0 7 1.0060086250305176\n",
      "0 8 1.0169541835784912\n",
      "0 9 0.9846461415290833\n",
      "0 10 0.999106764793396\n",
      "0 11 1.0048619508743286\n",
      "0 12 1.001754641532898\n",
      "0 13 0.9924237728118896\n",
      "0 14 0.9979787468910217\n",
      "0 15 0.9823379516601562\n",
      "0 16 0.9909963011741638\n",
      "0 17 1.011032223701477\n",
      "0 18 0.9704959392547607\n",
      "0 19 0.9552665948867798\n",
      "0 20 0.9864574670791626\n",
      "0 21 0.9903250336647034\n",
      "0 22 0.9571542143821716\n",
      "0 23 0.9692123532295227\n",
      "0 24 0.9748493432998657\n",
      "0 25 0.9815436005592346\n",
      "0 26 0.9642937183380127\n",
      "0 27 0.9472147226333618\n",
      "0 28 0.9742161631584167\n",
      "0 29 0.9546472430229187\n",
      "0 30 0.9545081257820129\n",
      "0 31 0.9851078987121582\n",
      "0 32 0.9420884251594543\n",
      "0 33 0.9295582175254822\n",
      "0 34 0.9630100727081299\n",
      "0 35 0.9397223591804504\n",
      "0 36 0.946564257144928\n",
      "0 37 0.9318797588348389\n",
      "0 38 0.9396010637283325\n",
      "1 39 0.9869094491004944\n",
      "1 40 0.9255378246307373\n",
      "1 41 0.9646530151367188\n",
      "1 42 0.9715306758880615\n",
      "1 43 0.9101486206054688\n",
      "1 44 0.9563069343566895\n",
      "1 45 0.9422851204872131\n",
      "1 46 0.9394258260726929\n",
      "1 47 0.9418042898178101\n",
      "1 48 0.9255371689796448\n",
      "1 49 0.9522467851638794\n",
      "1 50 0.9642285704612732\n",
      "1 51 0.9453305006027222\n",
      "1 52 0.9598363041877747\n",
      "1 53 0.9534865021705627\n",
      "1 54 0.9210606217384338\n",
      "1 55 0.920888364315033\n",
      "1 56 0.9231308698654175\n",
      "1 57 0.9294348359107971\n",
      "1 58 0.9348408579826355\n",
      "1 59 0.9542282819747925\n",
      "1 60 0.9262465834617615\n",
      "1 61 0.9625263214111328\n",
      "1 62 0.9450432658195496\n",
      "1 63 0.9676283001899719\n",
      "1 64 0.981319785118103\n",
      "1 65 0.9359257221221924\n",
      "1 66 0.9594751596450806\n",
      "1 67 0.9458135962486267\n",
      "1 68 0.9298748970031738\n",
      "1 69 0.9350731372833252\n",
      "1 70 0.9540793299674988\n",
      "1 71 0.9265488982200623\n",
      "1 72 0.966225802898407\n",
      "1 73 1.0021356344223022\n",
      "1 74 0.9718149900436401\n",
      "1 75 0.9517579078674316\n",
      "1 76 0.9232137799263\n",
      "1 77 0.9943526387214661\n",
      "2 78 0.9371815323829651\n",
      "2 79 0.9705796837806702\n",
      "2 80 0.9004572629928589\n",
      "2 81 0.9115103483200073\n",
      "2 82 0.9163694977760315\n",
      "2 83 0.9414361119270325\n",
      "2 84 0.9664126634597778\n",
      "2 85 0.9918608665466309\n",
      "2 86 0.9840073585510254\n",
      "2 87 0.9480005502700806\n",
      "2 88 0.994478166103363\n",
      "2 89 0.9781287312507629\n",
      "2 90 0.9280935525894165\n",
      "2 91 0.9518100023269653\n",
      "2 92 0.9382227063179016\n",
      "2 93 0.9223564863204956\n",
      "2 94 0.9441270232200623\n",
      "2 95 0.9310159087181091\n",
      "2 96 0.9612430334091187\n",
      "2 97 0.9492404460906982\n",
      "2 98 0.9733651280403137\n",
      "2 99 0.9577804803848267\n",
      "2 100 0.9327511787414551\n",
      "2 101 0.9174458384513855\n",
      "2 102 0.9554347991943359\n",
      "2 103 0.9269658327102661\n",
      "2 104 0.949506938457489\n",
      "2 105 0.9360107779502869\n",
      "2 106 0.9274922013282776\n",
      "2 107 0.9576185941696167\n",
      "2 108 0.9582527875900269\n",
      "2 109 0.9797962307929993\n",
      "2 110 0.9357048869132996\n",
      "2 111 0.9916219711303711\n",
      "2 112 0.9337161779403687\n",
      "2 113 0.9425383806228638\n",
      "2 114 0.9263095855712891\n",
      "2 115 0.9332515597343445\n",
      "2 116 0.9816527366638184\n",
      "3 117 0.978009819984436\n",
      "3 118 0.9594091176986694\n",
      "3 119 0.9092262983322144\n",
      "3 120 0.9116073250770569\n",
      "3 121 0.9708754420280457\n",
      "3 122 0.9916330575942993\n",
      "3 123 0.9518917202949524\n",
      "3 124 0.9293386936187744\n",
      "3 125 0.9575533270835876\n",
      "3 126 0.9144454002380371\n",
      "3 127 0.9857074022293091\n",
      "3 128 0.941963255405426\n",
      "3 129 0.9461186528205872\n",
      "3 130 0.9445440769195557\n",
      "3 131 0.9449474215507507\n",
      "3 132 0.908825695514679\n",
      "3 133 0.9629403948783875\n",
      "3 134 0.9551516175270081\n",
      "3 135 0.9504417181015015\n",
      "3 136 0.9465793967247009\n",
      "3 137 0.9264615774154663\n",
      "3 138 0.8939070701599121\n",
      "3 139 0.8883922100067139\n",
      "3 140 0.9380578994750977\n",
      "3 141 0.9278437495231628\n",
      "3 142 0.9419238567352295\n",
      "3 143 0.9527708888053894\n",
      "3 144 0.9259116649627686\n",
      "3 145 0.94203782081604\n",
      "3 146 0.9802263379096985\n",
      "3 147 0.9900619387626648\n",
      "3 148 0.9733376502990723\n",
      "3 149 0.9651201963424683\n",
      "3 150 0.9878940582275391\n",
      "3 151 0.9554039835929871\n",
      "3 152 0.9412645697593689\n",
      "3 153 0.9761001467704773\n",
      "3 154 0.9637884497642517\n",
      "3 155 0.9207856059074402\n",
      "4 156 0.9792200326919556\n",
      "4 157 0.9606919288635254\n",
      "4 158 0.909269392490387\n",
      "4 159 0.9570925831794739\n",
      "4 160 0.9579241275787354\n",
      "4 161 0.954078733921051\n",
      "4 162 0.9466208219528198\n",
      "4 163 0.9767510294914246\n",
      "4 164 0.9612787365913391\n",
      "4 165 0.949179470539093\n",
      "4 166 0.931443989276886\n",
      "4 167 0.9292052388191223\n",
      "4 168 0.930809497833252\n",
      "4 169 0.9276350140571594\n",
      "4 170 0.9725539684295654\n",
      "4 171 0.9511014819145203\n",
      "4 172 0.9304261803627014\n",
      "4 173 0.9265391230583191\n",
      "4 174 0.9675296545028687\n",
      "4 175 0.9685689210891724\n",
      "4 176 0.9394116997718811\n",
      "4 177 0.9555352926254272\n",
      "4 178 0.9247511625289917\n",
      "4 179 0.9408829808235168\n",
      "4 180 0.9540950655937195\n",
      "4 181 1.0091028213500977\n",
      "4 182 0.9163075685501099\n",
      "4 183 0.9237231612205505\n",
      "4 184 0.9473065733909607\n",
      "4 185 0.9700350761413574\n",
      "4 186 0.9623305797576904\n",
      "4 187 0.9509269595146179\n",
      "4 188 0.9331974387168884\n",
      "4 189 0.9583054184913635\n",
      "4 190 0.9678239822387695\n",
      "4 191 0.9256264567375183\n",
      "4 192 0.9128381013870239\n",
      "4 193 0.9492297172546387\n",
      "4 194 0.9154978394508362\n",
      "5 195 0.9836536049842834\n",
      "5 196 0.956138014793396\n",
      "5 197 0.951039731502533\n",
      "5 198 0.9348294138908386\n",
      "5 199 0.9334532618522644\n",
      "5 200 0.965955913066864\n",
      "5 201 0.9544236660003662\n",
      "5 202 0.9509769678115845\n",
      "5 203 0.9081325531005859\n",
      "5 204 0.9389820098876953\n",
      "5 205 0.9853214621543884\n",
      "5 206 0.9261400699615479\n",
      "5 207 0.947670042514801\n",
      "5 208 0.9938488006591797\n",
      "5 209 0.9392549991607666\n",
      "5 210 0.942578136920929\n",
      "5 211 0.9358268976211548\n",
      "5 212 0.9167786240577698\n",
      "5 213 0.9772776365280151\n",
      "5 214 0.9339556694030762\n",
      "5 215 1.0059528350830078\n",
      "5 216 0.9353743195533752\n",
      "5 217 0.9506769776344299\n",
      "5 218 0.9659000635147095\n",
      "5 219 0.967963457107544\n",
      "5 220 0.9172533750534058\n",
      "5 221 0.9925287365913391\n",
      "5 222 0.9342853426933289\n",
      "5 223 0.9376585483551025\n",
      "5 224 0.9091973900794983\n",
      "5 225 0.9242892265319824\n",
      "5 226 0.9415262341499329\n",
      "5 227 0.9361015558242798\n",
      "5 228 0.9293789863586426\n",
      "5 229 0.9654248952865601\n",
      "5 230 0.9666784405708313\n",
      "5 231 0.9312196373939514\n",
      "5 232 0.9451236128807068\n",
      "5 233 0.9005101919174194\n",
      "6 234 0.8929498195648193\n",
      "6 235 0.9325610995292664\n",
      "6 236 0.9419946670532227\n",
      "6 237 0.9805692434310913\n",
      "6 238 0.9092731475830078\n",
      "6 239 0.9430639147758484\n",
      "6 240 0.9958963394165039\n",
      "6 241 0.963100254535675\n",
      "6 242 0.9452682137489319\n",
      "6 243 0.9077279567718506\n",
      "6 244 1.0021610260009766\n",
      "6 245 0.9504216313362122\n",
      "6 246 0.9381212592124939\n",
      "6 247 0.937773585319519\n",
      "6 248 0.9586718082427979\n",
      "6 249 0.9605309963226318\n",
      "6 250 1.0067460536956787\n",
      "6 251 0.9199923276901245\n",
      "6 252 0.942034125328064\n",
      "6 253 0.9132732152938843\n",
      "6 254 0.9423273205757141\n",
      "6 255 1.006935715675354\n",
      "6 256 0.926121175289154\n",
      "6 257 0.9222161173820496\n",
      "6 258 0.9311437010765076\n",
      "6 259 0.9534351229667664\n",
      "6 260 0.9332207441329956\n",
      "6 261 0.9705075025558472\n",
      "6 262 0.952664315700531\n",
      "6 263 0.9668363928794861\n",
      "6 264 0.9474547505378723\n",
      "6 265 0.940794050693512\n",
      "6 266 0.9431094527244568\n",
      "6 267 0.9392934441566467\n",
      "6 268 0.9376523494720459\n",
      "6 269 0.9523581266403198\n",
      "6 270 0.9344353079795837\n",
      "6 271 0.9448143243789673\n",
      "6 272 1.0263522863388062\n",
      "7 273 0.997714102268219\n",
      "7 274 0.9644120335578918\n",
      "7 275 0.9544886350631714\n",
      "7 276 0.9275794625282288\n",
      "7 277 0.8816475868225098\n",
      "7 278 0.9332570433616638\n",
      "7 279 0.9420363306999207\n",
      "7 280 0.9151938557624817\n",
      "7 281 0.9537577629089355\n",
      "7 282 0.9396882057189941\n",
      "7 283 0.8972622156143188\n",
      "7 284 0.9969116449356079\n",
      "7 285 0.8974977731704712\n",
      "7 286 0.9578083753585815\n",
      "7 287 0.9510202407836914\n",
      "7 288 0.8997532725334167\n",
      "7 289 0.9487545490264893\n",
      "7 290 0.98684161901474\n",
      "7 291 0.9692519903182983\n",
      "7 292 0.9242236614227295\n",
      "7 293 0.956439733505249\n",
      "7 294 0.9231643080711365\n",
      "7 295 0.9553018808364868\n",
      "7 296 0.9515169858932495\n",
      "7 297 0.9727388620376587\n",
      "7 298 0.9114874005317688\n",
      "7 299 0.9533442258834839\n",
      "7 300 0.9505237340927124\n",
      "7 301 0.9669314026832581\n",
      "7 302 0.9782994389533997\n",
      "7 303 0.9591138958930969\n",
      "7 304 0.9738849997520447\n",
      "7 305 0.9287912845611572\n",
      "7 306 0.9305634498596191\n",
      "7 307 0.945279598236084\n",
      "7 308 0.9561570286750793\n",
      "7 309 0.9869424104690552\n",
      "7 310 0.9681110382080078\n",
      "7 311 0.9675580859184265\n",
      "8 312 0.9700871109962463\n",
      "8 313 0.9294180274009705\n",
      "8 314 0.9398347735404968\n",
      "8 315 0.8866615891456604\n",
      "8 316 0.968049943447113\n",
      "8 317 0.9425416588783264\n",
      "8 318 0.9549180865287781\n",
      "8 319 0.9321560263633728\n",
      "8 320 0.9753697514533997\n",
      "8 321 0.9853643178939819\n",
      "8 322 0.9513093829154968\n",
      "8 323 0.9136383533477783\n",
      "8 324 0.9287028312683105\n",
      "8 325 0.9337645173072815\n",
      "8 326 0.9778324365615845\n",
      "8 327 0.9534652829170227\n",
      "8 328 0.9509524703025818\n",
      "8 329 0.9133728742599487\n",
      "8 330 0.9659622311592102\n",
      "8 331 0.9693477749824524\n",
      "8 332 0.9280440211296082\n",
      "8 333 1.0031646490097046\n",
      "8 334 0.9741170406341553\n",
      "8 335 0.9385676980018616\n",
      "8 336 0.9316351413726807\n",
      "8 337 0.9566879868507385\n",
      "8 338 0.9414982795715332\n",
      "8 339 0.9724941253662109\n",
      "8 340 0.9322412610054016\n",
      "8 341 0.9730534553527832\n",
      "8 342 0.9053199291229248\n",
      "8 343 1.0026787519454956\n",
      "8 344 0.949298620223999\n",
      "8 345 0.915849506855011\n",
      "8 346 0.9208256602287292\n",
      "8 347 0.891654372215271\n",
      "8 348 0.9742274284362793\n",
      "8 349 0.9526048302650452\n",
      "8 350 0.9741027355194092\n",
      "9 351 0.937329888343811\n",
      "9 352 0.9870405197143555\n",
      "9 353 0.9537952542304993\n",
      "9 354 0.928680419921875\n",
      "9 355 0.943813681602478\n",
      "9 356 0.9365124106407166\n",
      "9 357 0.9133471250534058\n",
      "9 358 0.9712561964988708\n",
      "9 359 0.972609281539917\n",
      "9 360 0.9326808452606201\n",
      "9 361 0.9393088221549988\n",
      "9 362 0.9509477019309998\n",
      "9 363 0.9536722302436829\n",
      "9 364 0.9379704594612122\n",
      "9 365 0.9141280055046082\n",
      "9 366 0.9358807802200317\n",
      "9 367 0.9966616034507751\n",
      "9 368 0.9667358994483948\n",
      "9 369 0.953417181968689\n",
      "9 370 0.9413999915122986\n",
      "9 371 0.9401763677597046\n",
      "9 372 0.9699843525886536\n",
      "9 373 0.958970308303833\n",
      "9 374 0.9497724771499634\n",
      "9 375 0.9905271530151367\n",
      "9 376 0.9231007099151611\n",
      "9 377 0.9260650277137756\n",
      "9 378 0.9539501070976257\n",
      "9 379 0.9181796312332153\n",
      "9 380 0.9571448564529419\n",
      "9 381 0.9603915810585022\n",
      "9 382 0.8940898180007935\n",
      "9 383 0.9460453987121582\n",
      "9 384 0.9533491730690002\n",
      "9 385 0.9232378005981445\n",
      "9 386 0.9649217128753662\n",
      "9 387 0.9281924366950989\n",
      "9 388 0.9699593782424927\n",
      "9 389 0.993530809879303\n",
      "10 390 0.9494484066963196\n",
      "10 391 0.9710868000984192\n",
      "10 392 0.9293277859687805\n",
      "10 393 0.9620556235313416\n",
      "10 394 0.9535346627235413\n",
      "10 395 0.9402238130569458\n",
      "10 396 0.9401180744171143\n",
      "10 397 0.9287225604057312\n",
      "10 398 0.9676545262336731\n",
      "10 399 0.9378932118415833\n",
      "10 400 0.9103488922119141\n",
      "10 401 0.9659386873245239\n",
      "10 402 0.9604585766792297\n",
      "10 403 0.9437448978424072\n",
      "10 404 0.9102696180343628\n",
      "10 405 0.9654021859169006\n",
      "10 406 0.9490841031074524\n",
      "10 407 0.9500380754470825\n",
      "10 408 0.9604295492172241\n",
      "10 409 0.9440457224845886\n",
      "10 410 0.9281063079833984\n",
      "10 411 0.9463919997215271\n",
      "10 412 0.97458416223526\n",
      "10 413 0.9221545457839966\n",
      "10 414 0.9127482175827026\n",
      "10 415 0.970790684223175\n",
      "10 416 0.9613478183746338\n",
      "10 417 0.976540744304657\n",
      "10 418 0.9450827836990356\n",
      "10 419 0.9197215437889099\n",
      "10 420 0.9825844168663025\n",
      "10 421 0.9484553933143616\n",
      "10 422 0.9193044900894165\n",
      "10 423 0.9437426924705505\n",
      "10 424 0.9301425218582153\n",
      "10 425 0.946463406085968\n",
      "10 426 0.9851239919662476\n",
      "10 427 0.9732121229171753\n",
      "10 428 0.922441840171814\n",
      "11 429 0.9536433219909668\n",
      "11 430 0.9589940905570984\n",
      "11 431 0.9508631825447083\n",
      "11 432 0.9390154480934143\n",
      "11 433 0.9525560140609741\n",
      "11 434 0.971976101398468\n",
      "11 435 0.928537130355835\n",
      "11 436 0.988078773021698\n",
      "11 437 0.9450905323028564\n",
      "11 438 0.9535146355628967\n",
      "11 439 0.93769770860672\n",
      "11 440 0.9086429476737976\n",
      "11 441 0.9324551224708557\n",
      "11 442 0.9456608295440674\n",
      "11 443 0.936881959438324\n",
      "11 444 0.9762091040611267\n",
      "11 445 0.9264357686042786\n",
      "11 446 0.9969787001609802\n",
      "11 447 0.9180507659912109\n",
      "11 448 0.986305832862854\n",
      "11 449 0.9446802139282227\n",
      "11 450 0.9409019351005554\n",
      "11 451 0.9256688952445984\n",
      "11 452 0.9493793249130249\n",
      "11 453 0.9019875526428223\n",
      "11 454 0.9875795841217041\n",
      "11 455 0.9358261823654175\n",
      "11 456 0.9963513016700745\n",
      "11 457 0.9522339105606079\n",
      "11 458 0.9838499426841736\n",
      "11 459 0.9242750406265259\n",
      "11 460 0.9456220865249634\n",
      "11 461 0.933956503868103\n",
      "11 462 0.9581279754638672\n",
      "11 463 0.9531257152557373\n",
      "11 464 0.9091761708259583\n",
      "11 465 0.9761266708374023\n",
      "11 466 0.9244086742401123\n",
      "11 467 0.8574144244194031\n",
      "12 468 0.9728612303733826\n",
      "12 469 0.8981972336769104\n",
      "12 470 0.9729653596878052\n",
      "12 471 0.9446198344230652\n",
      "12 472 0.9732325077056885\n",
      "12 473 0.947380781173706\n",
      "12 474 0.9717854261398315\n",
      "12 475 0.9093427658081055\n",
      "12 476 0.9565705060958862\n",
      "12 477 0.9248382449150085\n",
      "12 478 0.9078053832054138\n",
      "12 479 0.9063394069671631\n",
      "12 480 0.9287899136543274\n",
      "12 481 0.9509878754615784\n",
      "12 482 0.9045222401618958\n",
      "12 483 0.9359717965126038\n",
      "12 484 0.9170787334442139\n",
      "12 485 0.9307695627212524\n",
      "12 486 0.9568524360656738\n",
      "12 487 0.9744959473609924\n",
      "12 488 0.9892916679382324\n",
      "12 489 0.9685986042022705\n",
      "12 490 0.9651522040367126\n",
      "12 491 0.9224661588668823\n",
      "12 492 0.9794924259185791\n",
      "12 493 0.9592716097831726\n",
      "12 494 0.9416282773017883\n",
      "12 495 0.9314752817153931\n",
      "12 496 0.9996520280838013\n",
      "12 497 0.9294947385787964\n",
      "12 498 0.9255802631378174\n",
      "12 499 0.9356025457382202\n",
      "12 500 0.9438650012016296\n",
      "12 501 0.9477880597114563\n",
      "12 502 0.9537166357040405\n",
      "12 503 1.022763729095459\n",
      "12 504 0.9578878879547119\n",
      "12 505 0.9423906207084656\n",
      "12 506 0.9825364947319031\n",
      "13 507 0.94855135679245\n",
      "13 508 0.9675139784812927\n",
      "13 509 0.9493447542190552\n",
      "13 510 0.9392490983009338\n",
      "13 511 0.9384635090827942\n",
      "13 512 0.9427577257156372\n",
      "13 513 0.9413312673568726\n",
      "13 514 0.9570896625518799\n",
      "13 515 0.922238290309906\n",
      "13 516 0.9209018349647522\n",
      "13 517 0.9319797158241272\n",
      "13 518 0.9504172205924988\n",
      "13 519 0.945070207118988\n",
      "13 520 0.9141055345535278\n",
      "13 521 0.957700788974762\n",
      "13 522 0.9695411324501038\n",
      "13 523 0.9142764806747437\n",
      "13 524 0.978097677230835\n",
      "13 525 0.9507607817649841\n",
      "13 526 0.9496877789497375\n",
      "13 527 0.9709436893463135\n",
      "13 528 0.9442372918128967\n",
      "13 529 0.9608911275863647\n",
      "13 530 0.9982403516769409\n",
      "13 531 0.948010265827179\n",
      "13 532 0.9346910715103149\n",
      "13 533 0.9250946044921875\n",
      "13 534 0.9125340580940247\n",
      "13 535 0.9241484999656677\n",
      "13 536 0.9754894375801086\n",
      "13 537 0.965355396270752\n",
      "13 538 0.9501039385795593\n",
      "13 539 0.9486031532287598\n",
      "13 540 0.9770985841751099\n",
      "13 541 0.9145869016647339\n",
      "13 542 0.9347638487815857\n",
      "13 543 0.9691792726516724\n",
      "13 544 0.9912059903144836\n",
      "13 545 0.9204931855201721\n",
      "14 546 0.9293789267539978\n",
      "14 547 0.9433459043502808\n",
      "14 548 0.963451623916626\n",
      "14 549 0.9059358239173889\n",
      "14 550 0.9254705905914307\n",
      "14 551 0.9917495250701904\n",
      "14 552 0.9502090215682983\n",
      "14 553 0.970230221748352\n",
      "14 554 0.9885892868041992\n",
      "14 555 0.9495162963867188\n",
      "14 556 0.9333401322364807\n",
      "14 557 0.9616334438323975\n",
      "14 558 0.9718643426895142\n",
      "14 559 0.9327695965766907\n",
      "14 560 0.954550564289093\n",
      "14 561 0.9671754240989685\n",
      "14 562 0.9521166086196899\n",
      "14 563 0.9596765637397766\n",
      "14 564 0.9188228249549866\n",
      "14 565 0.9237110614776611\n",
      "14 566 0.9160299301147461\n",
      "14 567 0.9046909809112549\n",
      "14 568 0.944389283657074\n",
      "14 569 0.9615762233734131\n",
      "14 570 0.9642096161842346\n",
      "14 571 0.9519824385643005\n",
      "14 572 0.9691166281700134\n",
      "14 573 0.9258800148963928\n",
      "14 574 0.961476743221283\n",
      "14 575 0.9316174983978271\n",
      "14 576 0.966209888458252\n",
      "14 577 0.9505849480628967\n",
      "14 578 0.9679850339889526\n",
      "14 579 0.9744130373001099\n",
      "14 580 0.9396167397499084\n",
      "14 581 0.9694662094116211\n",
      "14 582 0.9125748872756958\n",
      "14 583 0.9065172076225281\n",
      "14 584 0.9572269320487976\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = select_target(i=5)\n",
    "model = train(dataloader=train_loader, lr=0.001, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6aa18fb7-1f4d-46dd-9f74-60bca3437dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    for seq, labels in dataloader:\n",
    "        output = model(seq.float())\n",
    "        pred_labels = torch.argmax(output, dim=1)\n",
    "        acc = (pred_labels == labels).float().mean().item()\n",
    "        print(acc)\n",
    "        print(pred_labels)\n",
    "        print(\"##########################\")\n",
    "        print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33fdceb6-ff38-4207-ba8d-5510a311d1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6240000128746033\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "##########################\n",
      "tensor([0, 0, 0, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2,\n",
      "        2, 1, 1, 2, 2, 0, 2, 1, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 0, 0, 2,\n",
      "        2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 0,\n",
      "        1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 1, 2, 0, 2, 1, 1, 2, 0,\n",
      "        2, 1, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
      "        0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 2,\n",
      "        0, 0, 1, 2, 2, 1, 2, 0, 2, 2, 0, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 0, 2,\n",
      "        0, 2, 2, 0, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2, 2,\n",
      "        2, 1, 1, 0, 2, 0, 2, 2, 1, 2, 2, 0, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 0, 2,\n",
      "        2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
      "        0, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1,\n",
      "        2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 0, 0,\n",
      "        1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 0, 1, 1, 1,\n",
      "        2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 1, 0, 1, 2, 0, 2, 0, 2, 1,\n",
      "        0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n",
      "        0, 2, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1,\n",
      "        2, 0, 0, 1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 2,\n",
      "        0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2,\n",
      "        2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 1, 0, 2, 2, 1, 0, 1, 0, 2, 2, 1,\n",
      "        2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2])\n",
      "0.6060000061988831\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "##########################\n",
      "tensor([2, 1, 2, 1, 0, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
      "        0, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2,\n",
      "        2, 2, 2, 1, 2, 1, 0, 1, 1, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 1,\n",
      "        1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n",
      "        2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1,\n",
      "        0, 2, 0, 1, 2, 2, 2, 0, 1, 0, 1, 2, 2, 2, 2, 2, 1, 0, 2, 0, 0, 1, 2, 2,\n",
      "        2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 1, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2,\n",
      "        2, 2, 2, 2, 2, 1, 0, 1, 2, 2, 0, 1, 2, 0, 0, 2, 2, 1, 0, 2, 2, 0, 1, 0,\n",
      "        0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
      "        0, 2, 1, 2, 1, 2, 2, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0,\n",
      "        0, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2,\n",
      "        0, 1, 2, 2, 1, 2, 2, 2, 0, 1, 2, 0, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
      "        0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 2, 2,\n",
      "        2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
      "        1, 2, 2, 0, 2, 2, 0, 2, 1, 1, 1, 2, 1, 2, 2, 0, 0, 2, 1, 0, 2, 2, 0, 2,\n",
      "        2, 2, 2, 1, 1, 2, 2, 1, 0, 2, 0, 1, 0, 2, 2, 2, 0, 2, 1, 2, 1, 0, 1, 0,\n",
      "        0, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 1, 2,\n",
      "        2, 0, 0, 1, 1, 2, 0, 2, 1, 0, 2, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0, 1,\n",
      "        2, 2, 1, 0, 2, 2, 2, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 0, 0, 1,\n",
      "        1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 2, 2, 2, 2, 0, 1, 2, 0, 0])\n",
      "0.6039999723434448\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "##########################\n",
      "tensor([2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2,\n",
      "        0, 1, 2, 1, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 1, 0, 2, 2, 2, 0, 2,\n",
      "        2, 2, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 0, 1, 2, 1, 2, 2, 0, 1, 2, 2,\n",
      "        2, 0, 1, 1, 1, 2, 2, 0, 0, 2, 2, 0, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 1, 2, 2,\n",
      "        0, 0, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0,\n",
      "        2, 2, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
      "        1, 2, 1, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0,\n",
      "        2, 2, 2, 2, 1, 0, 1, 2, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 1, 0, 2, 0, 0, 2,\n",
      "        2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 1, 0, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 1,\n",
      "        2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2, 0, 2, 1, 2, 2, 2, 2,\n",
      "        1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 1, 1, 2,\n",
      "        2, 2, 0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 2, 0, 0, 0, 2, 0,\n",
      "        2, 2, 1, 2, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 1, 0,\n",
      "        2, 2, 1, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 2,\n",
      "        2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 1, 0, 2, 0, 1, 2, 2, 2, 0,\n",
      "        2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 1, 0, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2,\n",
      "        2, 0, 1, 2, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2,\n",
      "        1, 2, 2, 0, 0, 2, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 0, 0, 2, 2, 1, 2, 1,\n",
      "        2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 2])\n",
      "0.6140000224113464\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "##########################\n",
      "tensor([2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0,\n",
      "        2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0,\n",
      "        2, 2, 2, 1, 2, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2,\n",
      "        2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        0, 0, 2, 2, 1, 2, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2,\n",
      "        1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2,\n",
      "        0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 1, 1, 0, 0, 2, 2,\n",
      "        2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 2,\n",
      "        2, 1, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 0,\n",
      "        2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 0, 2,\n",
      "        2, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 2, 0, 1, 1, 2, 2, 1, 2, 2, 0, 2, 1, 2,\n",
      "        2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 2,\n",
      "        2, 2, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 1, 2, 2, 1, 2, 1, 0, 2, 1, 2, 2, 0,\n",
      "        0, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 0, 1,\n",
      "        2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 1, 2, 2, 1, 2, 0, 0, 2, 2, 1, 1,\n",
      "        0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2,\n",
      "        1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 2, 0, 1,\n",
      "        2, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 2, 2, 0, 2, 2, 1,\n",
      "        0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2,\n",
      "        0, 2, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 2, 0, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 0, 2, 1, 1, 2, 2])\n",
      "0.6075000166893005\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "##########################\n",
      "tensor([2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 2, 1, 0,\n",
      "        1, 2, 0, 1, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2,\n",
      "        2, 0, 2, 1, 1, 0, 2, 2, 2, 2, 0, 2, 1, 2, 0, 2, 2, 0, 0, 2, 2, 1, 1, 2,\n",
      "        2, 2, 0, 2, 2, 0, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2,\n",
      "        2, 2, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 1, 0, 0, 2, 0, 1,\n",
      "        2, 2, 2, 1, 0, 1, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2,\n",
      "        0, 2, 2, 2, 1, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 1, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 1, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
      "        2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2,\n",
      "        1, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 1, 2, 2, 0, 0, 2, 2,\n",
      "        2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 2, 1, 2, 0,\n",
      "        2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 2, 0, 2, 2, 2, 0, 0, 2,\n",
      "        2, 0, 1, 0, 0, 2, 2, 1, 0, 0, 2, 0, 2, 2, 2, 0, 2, 1, 0, 2, 2, 0, 0, 2,\n",
      "        2, 1, 1, 2, 0, 2, 1, 2, 2, 0, 2, 1, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2,\n",
      "        2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
      "        1, 2, 0, 2, 2, 0, 0, 1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2,\n",
      "        0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 1, 1, 2, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3384cc0-54c5-4508-a9ee-c3bf5be1a696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env2",
   "language": "python",
   "name": "virtual_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
